{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# code done better\n",
    "https://medium.com/diogo-menezes-borges/project-3-analytics-vidhya-hackaton-black-friday-f6c6bf3da86f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-6f394ca96932>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-6f394ca96932>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    test = pd.read_csv(\"data/test.csv\")train.head()\u001b[0m\n\u001b[0m                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#To visualize the whole grid\n",
    "pd.options.display.max_columns = 999#Kaggle divides the dataset already into Train and Test data\n",
    "train = pd.read_csv(\"data/train.csv\")\n",
    "test = pd.read_csv(\"data/test.csv\")train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "idsUnique = len(set(train.User_ID))\n",
    "idsTotal = train.shape[0]\n",
    "idsDupli = idsTotal — idsUnique\n",
    "print(“There are “ + str(idsDupli) + “ duplicate IDs for “ + str(idsTotal) + “ total entries”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(‘fivethirtyeight’)\n",
    "plt.figure(figsize=(12,7))\n",
    "sns.distplot(train.Purchase, bins = 25)\n",
    "plt.xlabel(“Amount spent in Purchase”)\n",
    "plt.ylabel(“Number of Buyers”)\n",
    "plt.title(“Purchase amount Distribution”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (“Skew is:”, train.Purchase.skew())\n",
    "print(“Kurtosis: %f” % train.Purchase.kurt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = train.select_dtypes(include=[np.number])\n",
    "numeric_features.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(train.Occupation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = numeric_features.corr()print (corr[‘Purchase’].sort_values(ascending=False)[:10], ‘\\n’)\n",
    "print (corr[‘Purchase’].sort_values(ascending=False)[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation matrix\n",
    "f, ax = plt.subplots(figsize=(20, 9))\n",
    "sns.heatmap(corr, vmax=.8,annot_kws={'size': 20}, annot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(train.Gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(train.Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(train.City_Category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(train.Stay_In_Current_City_Years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Occupation_pivot = \\\n",
    "train.pivot_table(index='Occupation', values=\"Purchase\", aggfunc=np.mean)Occupation_pivot.plot(kind='bar', color='blue',figsize=(12,7))\n",
    "plt.xlabel(\"Occupation\")\n",
    "plt.ylabel(\"Purchase\")\n",
    "plt.title(\"Occupation and Purchase Analysis\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join Train and Test Dataset\n",
    "train[‘source’]=’train’\n",
    "test[‘source’]=’test’data = pd.concat([train,test], ignore_index = True, sort = False)print(train.shape, test.shape, data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the percentage of null values per variable\n",
    "data.isnull().sum()/data.shape[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Product_Category_2\"]= \\\n",
    "data[\"Product_Category_2\"].fillna(-2.0).astype(\"float\")data.Product_Category_2.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[“Product_Category_3”]= \\\n",
    "data[“Product_Category_3”].fillna(-2.0).astype(“float”)\n",
    "data.Product_Category_3.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get index of all columns with product_category_1 equal 19 or 20 from train\n",
    "condition = data.index[(data.Product_Category_1.isin([19,20])) & (data.source == “train”)]\n",
    "data = data.drop(condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply function len(unique()) to every data variable\n",
    "data.apply(lambda x: len(x.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter categorical variables and get dataframe will all strings columns names except Item_identfier and outlet_identifier\n",
    "category_cols = data.select_dtypes(include=[‘object’]).columns.drop([“source”])\n",
    "#Print frequency of categories\n",
    "for col in category_cols:\n",
    " #Number of times each value appears in the column\n",
    " frequency = data[col].value_counts()\n",
    " print(“\\nThis is the frequency distribution for “ + col + “:”)\n",
    " print(frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn gender binary\n",
    "gender_dict = {‘F’:0, ‘M’:1}\n",
    "data[“Gender”] = data[“Gender”].apply(lambda line: gender_dict[line])data[“Gender”].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Giving Age Numerical values\n",
    "age_dict = {‘0–17’:0, ‘18–25’:1, ‘26–35’:2, ‘36–45’:3, ‘46–50’:4, ‘51–55’:5, ‘55+’:6}\n",
    "data[“Age”] = data[“Age”].apply(lambda line: age_dict[line])data[“Age”].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_dict = {‘A’:0, ‘B’:1, ‘C’:2}\n",
    "data[“City_Category”] = data[“City_Category”].apply(lambda line: city_dict[line])data[“City_Category”].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import library:\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()#New variable for outlet\n",
    "data['Stay_In_Current_City_Years'] = le.fit_transform(data['Stay_In_Current_City_Years'])\n",
    "    \n",
    "#Dummy Variables:\n",
    "data = pd.get_dummies(data, columns=['Stay_In_Current_City_Years'])data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature representing the count of each user\n",
    "def getCountVar(compute_df, count_df, var_name):\n",
    "    grouped_df = count_df.groupby(var_name)\n",
    "    count_dict = {}\n",
    "    for name, group in grouped_df:\n",
    "        count_dict[name] = group.shape[0]count_list = []\n",
    "    for index, row in compute_df.iterrows():\n",
    "        name = row[var_name]\n",
    "        count_list.append(count_dict.get(name, 0))\n",
    "    return count_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[“User_ID_Count”] = getCountVar(data, data, “User_ID”)\n",
    "data[“Age_Count”] =getCountVar(data, data, “Age”)\n",
    "data[“Occupation_Count”] =getCountVar(data, data, “Occupation”)\n",
    "data[“Product_Category_1_Count”] =getCountVar(data, data,”Product_Category_1\")\n",
    "data[“Product_Category_2_Count”] =getCountVar(data, data, “Product_Category_2”)\n",
    "data[“Product_Category_3_Count”] =getCountVar(data, data,”Product_Category_3\")\n",
    "data[“Product_ID_Count”] =getCountVar(data, data, “Product_ID”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide into test and train:\n",
    "train = data.loc[data[‘source’]==”train”]\n",
    "test = data.loc[data[‘source’]==”test”]#Drop unnecessary columns:\n",
    "test.drop([‘source’],axis=1,inplace=True)\n",
    "train.drop([‘source’],axis=1,inplace=True)#Export files as modified versions:\n",
    "train.to_csv(“data/train_modified.csv”,index=False)\n",
    "test.to_csv(“data/test_modified.csv”,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train_modified.csv')\n",
    "test_df = pd.read_csv('data/test_modified.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define target and ID columns:\n",
    "target = 'Item_Outlet_Sales'\n",
    "IDcol = ['Item_Identifier','Outlet_Identifier']#Define target and ID columns:\n",
    "target = 'Purchase'\n",
    "IDcol = ['User_ID','Product_ID']\n",
    "from sklearn import cross_validation, metricsdef modelfit(alg, dtrain, dtest, predictors, target, IDcol, filename):\n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], dtrain[target])\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])#Perform cross-validation:\n",
    "    cv_score = cross_validation.cross_val_score(alg, dtrain[predictors],(dtrain[target]) , cv=20, scoring='neg_mean_squared_error')\n",
    "    cv_score = np.sqrt(np.abs(cv_score))\n",
    "    \n",
    "    #Print model report:\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"RMSE : %.4g\" % np.sqrt(metrics.mean_squared_error((dtrain[target]).values, dtrain_predictions)))\n",
    "    print(\"CV Score : Mean - %.4g | Std - %.4g | Min - %.4g | Max - %.4g\" % (np.mean(cv_score),np.std(cv_score),np.min(cv_score),np.max(cv_score)))\n",
    "    \n",
    "    #Predict on testing data:\n",
    "    dtest[target] = alg.predict(dtest[predictors])\n",
    "    \n",
    "    #Export submission file:\n",
    "    IDcol.append(target)\n",
    "    submission = pd.DataFrame({ x: dtest[x] for x in IDcol})\n",
    "    submission.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "LR = LinearRegression(normalize=True)predictors = train_df.columns.drop(['Purchase','Product_ID','User_ID'])\n",
    "modelfit(LR, train_df, test_df, predictors, target, IDcol, 'LR.csv')coef1 = pd.Series(LR.coef_, predictors).sort_values()\n",
    "coef1.plot(kind='bar', title='Model Coefficients')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "RR = Ridge(alpha=0.05,normalize=True)\n",
    "modelfit(RR, train_df, test_df, predictors, target, IDcol, ‘RR.csv’)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "DT = DecisionTreeRegressor(max_depth=15, min_samples_leaf=100)\n",
    "modelfit(DT, train_df, test_df, predictors, target, IDcol, ‘DT.csv’)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = DecisionTreeRegressor(max_depth=8, min_samples_leaf=150)\n",
    "modelfit(RF, train_df, test_df, predictors, target, IDcol, ‘RF.csv’)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressormy_model = XGBRegressor(n_estimators=1000, learning_rate=0.05)\n",
    "my_model.fit(train_df[predictors], train_df[target], early_stopping_rounds=5, \n",
    "             eval_set=[(test_df[predictors], test_df[target])], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict training set:\n",
    "train_df_predictions = my_model.predict(train_df[predictors])# make predictions\n",
    "predictions = my_model.predict(test_df[predictors])from sklearn.metrics import mean_absolute_error\n",
    "print(\"Mean Absolute Error : \" + str(mean_absolute_error(predictions, test_df[target])))\n",
    "print(\"RMSE : %.4g\" % np.sqrt(metrics.mean_squared_error((train_df[target]).values, train_df_predictions)))IDcol.append(target)\n",
    "    submission = pd.DataFrame({ x: test_df[x] for x in IDcol})\n",
    "    submission.to_csv(\"XGBoost.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
